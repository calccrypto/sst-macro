% !TEX root = developer.tex

\newcommand{\nodecls}{\inlinecode{node}\xspace}
\newcommand{\topcls}{\inlinecode{topology}\xspace}
\newcommand{\switchid}{\inlinecode{switch_id}\xspace}
\newcommand{\nodeid}{\inlinecode{node_id}\xspace}

\chapter{Hardware Models}
\label{chapter:hardware}

\section{Connectables}
\label{sec:connectables}
While in common usage, \sstmacro follows a well-defined machine model (see below),
it generally allows any set of components to be connected. 
As discussed in Chapter \ref{chapter:des}, the simulation proceeds by having event components exchange messages,
each scheduled to arrive at a specific time.
\sstmacro provides a generic interface for any set of hardware components to be linked together.
Any hardware component that connects to other components and exchanges messages must inherit from the \inlinecode{connectable} class.
The \inlinecode{connectable} class presents a standard virtual interface

\begin{CppCode}
class connectable
{
 public:
  virtual void
  connect(
    int src_outport,
    int dst_inport,
    connection_type_t ty,
    connectable* mod,
    config* cfg) = 0;
};
\end{CppCode}

First, port numbers must be assigned identifying the output port at the source and in the input port at the destination.
For example, a switch may have several outgoing connections, each of which must be assigned a unique port number.
The connection must be configured at both source and destination.
The function is called twice for each side of the connection. If we have a source and destination:

\begin{CppCode}
connectable* src = ...
connectable* dst = ...
connectable::config cfg = ...
src->connect(inport, outport, Output, dst, &cfg);
dst->connect(inport, outport, Input, src, &cfg);
\end{CppCode}

The ``direction'' of the link as input or output is identified by \inlinecode{connection_type_t}.


A certain style and set of rules is recommended for all connectables.
If these rules are ignored, setting up connections can quicky become confusing and produce difficult to maintain code.
The first and most important rule is that \inlinecode{connectables} never make their own connections.
Some ``meta''-object should create connections between objects.
In general, this work is left to a \inlinecode{topology} object.
An object should never be responsible for knowing about the ``world'' outside itself.
A topology or interconnect tells the object to make a connection rather than the object deciding to make the connection itself.
This will be illustrated below in \ref{sec:topology}.

The second rule to follow is that a connect function should never call another connect function.
In general, a single call to a connect function should create a single link.
If connect functions start calling other connect functions, you can end up a with a recursive mess.
If you need a bidirectional link (A $\rightarrow$ B, B $\rightarrow$ A),
two separate function calls should be made

\begin{CppCode}
A->connect(B);
B->connect(A);
\end{CppCode}

rather than having, e.g. A create a bidirectional link.

The first two rules should be considered rigorous. 
A third recommended rule is that all port numbers should be non-negative, and, in most cases, should start numbering from zero.


Combining the factory system for polymorphic types and the connectable system for building arbitrary machine links and topologies,
\sstmacro provides flexibility for building essentially any machine model you want.
However, \sstmacro provides a recommended machine structure to guide constructing machine models.

\section{Interconnect}\label{sec:topInterconnect}
For all standard runs, the entire hardware model is driven by the interconnect object.
The interconnect creates nodes, creates network switches, chooses a topology, and connects all of the network endpoints together.
In this regard, the interconnect also choose what types of components are being connected together.
For example, if you were going to introduce some custom FPGA device that connects to the nodes to perform filesystem operations,
the interconnect is responsible for creating it.

To illustrate, here is the code for the interconnect that creates the node objects. 
The interconnect is itself a factory object, configured from a parameter file.

\begin{CppCode}
void
interconnect::init_factory_params(sprockit::sim_parameters* params)
{
  sprockit::sim_parameters* top_params = params->get_namespace("topology");
  topology_ = topology_factory::get_param("name", top_params);
  
  endpoint_map nodes;
  sprockit::sim_parameters* node_params = params->get_namespace("node");
  sprockit::factory<connectable>* node_builder
    = new sprockit::template_factory<connectable, node_factory>(node_params->get_param("model"));
  topology_->build_endpoint_connectables(nodes, node_builder, partition_, rt_->me(), node_params);
}
\end{CppCode}

The interconnect creates a topology and factory builder for the nodes.
Note here the use of parameter namespaces to isolate parameters.
This continues for the NIC and switches.

\begin{CppCode}
  endpoint_map nics;
  sprockit::sim_parameters* nic_params = params->get_namespace("nic");
  sprockit::factory2<connectable>* nic_builder
    = new sprockit::template_factory2<connectable, nic_factory>(nic_params->get_param("model"));
  topology_->build_interface_connectables(1, nics, nic_builder, partition_, rt_->me(), nic_pa
\end{CppCode}

\begin{CppCode}
  internal_map switches;
  sprockit::sim_parameters* switch_params = params->get_namespace("switch");
  sprockit::factory<connectable>* switch_builder
    = new sprockit::template_factory<connectable, network_switch_factory>(switch_params->get_param("model"));
  network_switch* dummy = new dist_dummy_switch(switch_id());
  topology_->build_internal_connectables(switches, switch_builder, partition_, rt_->me(), switch_params, dummy);
\end{CppCode}
Some special parameters (dummy switches) are important for MPI parallel simulations,
but these can be ignored for now.

Once these components are constructed, the topology connects them.
\begin{CppCode}
  topology_->connect_end_points(switches_, nics_);
  topology_->connect_topology(switches_);
\end{CppCode}

\section{Node}\label{sec:node}
Although the \nodecls can be implemented as a very complex model, it fundamentally only requires a single set of functions to meet the public interface.
The \nodecls must provide \inlinecode{execute_kernel} functions that are invoked by the \inlinecode{operating_system} or other other software objects.
The prototypes for these are:

\begin{CppCode}
  virtual void
  execute_kernel(ami::COMP_FUNC func, event* data);

  virtual void
  execute_kernel(ami::COMM_FUNC func, event* data);
\end{CppCode}	

By default, the abstract \nodecls class throws an \inlinecode{sprockit::unimplemented_error}. These functions are not pure virtual.
A node is only required to implement those functions that it needs to do.
The various function parameters are enums for the different operations a node may perform:
computation or communication.
The distinction between computation and hardware is subtle.
Hardware operations are things like interrupts, device resets, device failures.
They are not necessarily ``kernels'' in the standard parlance.

To illustrate a single example, we show the code that handles the function call

\begin{CppCode}
node->execute_kernel(ami::AMI_COMM_SEND, msg);
\end{CppCode}

leads to

\begin{CppCode}
  switch (func) {
    case sstmac::sw::ami::AMI_COMM_SEND: 
    {
      network_message* netmsg = ptr_safe_cast(network_message, data);
      netmsg->set_fromaddr(my_id_);
      if (netmsg->toaddr() == nodeid_) {
      	/* Intranode send */
      }
      else {
        nic_->send(netmsg);
      }
    }  
\end{CppCode}
All dynamic casts are routed through a special macro \inlinecode{safe_cast} for most types or \inlinecode{ptr_safe_cast} for smart pointer types.

\section{Network Interface (NIC)}\label{sec:nic}
The network interface can implement many services, but the basic public interface requires the NIC to do three things:

\begin{itemize}
\item Inject messages into the network
\item Receive messages ejected from the network
\item Deliver ACKs (acknowledgments) of message delivery
\end{itemize}

For sending messages, the NIC must implement

\begin{CppCode}
  virtual void
  do_send(network_message* payload);
\end{CppCode}
A non-virtual, top-level \inlinecode{send} function performs operations standard to all NICs.
Once these operations are complete, the NIC invokes \inlinecode{do_send} to perform model-specific send operations.
The NIC should only ever send \inlinecode{network_message} types.

For the bare-bones class \inlinecode{null_nic}, the function is

\begin{CppCode}
  injector_->handle(msg);
  if (msg->get_needs_ack()) {
    sst_message* acker = msg->clone_ack();
    schedule(now(), parent_node_, acker);
  }
\end{CppCode}
After injecting, the NIC creates an ACK and delivers the notification to the \nodecls.
In general, all arriving messages or ACKs should be delivered to the node.
The node is responsible for generating any software events in the OS.

For receiving, messages can be moved across the network and delivered in two different ways:
either at the byte-transfer layer (BTL) or message-transfer layer (MTL).
Depending on the congestion model, a large message (say a 1 MB MPI message) might be broken up into many packets.
These message chunks are moved across the network independently and then reassembled at the receiving end.
Alternatively, for flow models or simple analytical models, the message is not packetized and instead delivered as a single whole.
The methods are not pure virtual.  Depending on the congestion model,  the NIC might only implement chunk receives or whole receives.
Upon receipt, just as for ACKs, the NIC should deliver the message to the node to interpret.
In general, \inlinecode{nic::handle} is intended to handle packets. 
If a NIC supports direct handling of complete messages (MTL) instead of packets (BTL),
it should provide a message handler:

\begin{CppCode}
event_handler*
mtl_handler() const {
  return mtl_handler_;
}
\end{CppCode}

A special completion queue object tracks chunks and processes out-of-order arrivals,
notifying the NIC when the entire message is done.

\section{Memory Model}\label{sec:memModel}
As with the NIC and node, the memory model class can have a complex implementation under the hood,
but it must funnel things through the a common function.

\begin{CppCode}
virtual void
access(long bytes, double max_bw) = 0;
\end{CppCode}

This function is intended to be called from an application user-space thread.
As such, it should block until complete.
For more details on the use of user-space threading to model applications,
see the User's manual.


\section{Network Switch}\label{sec:networkSwitch}

Unlike the other classes above, a network switch is not required to implement any specific functions.
It is only required to be an \inlinecode{event_handler}, providing the usual \inlinecode{handle(event* ev)}.
The internal details can essentially be arbitrary.
However, the basic scheme for most switches follows the code below for the \inlinecode{packet_flow} model.

\begin{CppCode}
  packet_flow_interface* fpack = interface_cast(packet_flow_interface, ev);
  switch (fpack->type()) {
    case packet_flow_interface::credit: {
      packet_flow_credit* credit = static_cast<packet_flow_credit*>(fpack);
      out_buffers_[credit->port()]->handle_credit(credit);
      break;
    }
    case packet_flow_interface::payload: {
      packet_flow_payload* payload = static_cast<packet_flow_payload*>(fpack);
      router_->route(payload);
      xbar_->handle_payload(payload);
      break;
    }
  }
\end{CppCode}
The arriving event is determined to either be a new packet or a credit.
If a packet, the router object selects the next destination (port).
The packet is then passed to the crossbar for arbitration.

\section{Topology}
\label{sec:topology}
Of critical importance for the network modeling is the topology of the interconnect.
Common examples are the torus, fat tree, or butterfly.
To understand what these topologies are, there are many resources on the web.
Regardless of the actual structure as a torus or tree, the topology should present a common interface to the interconnect and NIC for routing messages.
Here we detail the public interface.
\subsection{Basic Topology}
Not all topologies are ``regular'' like a torus.  Ad hoc computer networks (like the internet) are ordered with IP addresses, but don't follow a regular geometric structure.
The abstract topology base class is intended to cover both cases.
Irregular or arbitrary topology connections are not fully supported yet.

The most important functions in the \topcls class are

\begin{CppCode}
class topology
{

  virtual std::vector<node_id>
  get_nodes_connected_to_switch(switch_id swid) const = 0;

  virtual long
  num_switches() const = 0;

  virtual long
  num_nodes() const = 0;

  virtual void
  connect_objects(connectable_map& objects) = 0;

  virtual switch_id
  node_to_injection_switch(node_id nodeaddr, int& switch_port) const = 0;

  virtual switch_id
  node_to_ejection_switch(node_id nodeaddr, int& switch_port) const = 0;

  virtual void
  minimal_route_to_switch(
    switch_id current_sw_addr,
    switch_id dest_sw_addr,
    routable::path& path) const = 0;

  virtual int
  num_hops_to_node(node_id src, node_id dst) const = 0;


\end{CppCode}

These functions are documented in the \inlineshell{topology.h} header file.
The first few functions just give the number of switches, number of nodes, and finally which nodes are connected to a given switch.
The most critical function for a topology is the \inlinecode{connect_objects} function that takes a list of objects and actually forms the links between them.
Each compute node will be connected to an injector switch and an ejector switch (often the same switch).
The topology must provide a mapping between a node and its ejection and injection points.
Additionally, the topology must indicate a port number or offset for the injection in case the switch has many nodes injecting to it.
The most important thing to distinguish here are \nodeid and \switchid types.
These are typedefs that distinguish between a switch or internal object in the topology and a node or network endpoint.

Besides just forming the connections, a topology is responsible for routing.
Given a source switch and the final destination, a topology must fill out path information.

\begin{CppCode}
struct path {
    int outport;
    int vc;
    int geometric_id;
    sprockit::metadata_bits<uint32_t> metadata;
}
\end{CppCode}

The most important information is the outport, telling a switch which port to route along to arrive at the destination.
More detail can be given with dimension and direction for some topologies (i.e. +X or -X in a torus).
For congestion models with channel dependencies, the virtual channel must also be given to avoid deadlock.
In general, network switches and other devices should be completely topology-agnostic.
The switch is responsible for modeling congestion within itself - crossbar arbitration, credits, outport multiplexing.
The switch is not able to determine for itself which outport to route along.
The topology tells the switch which port it needs and the switch determines what sort of congestion delay to expect on that port.
This division of labor is complicated a bit by adaptive routing, but remains essentially the same.  More details are given later.

\subsection{Structured Topology}\label{subsec:structuredTopology}

The structured topology assumes a regular, ordered connecting of nodes like a torus.
It is synonymous with any topology that can be mapped onto a coordinate system.
This is true even of tree structures for which the coordinates define which branch/leaf.
The structured topology introduces a few extra virtual functions:

\begin{CppCode}
class structured_topology :
  public topology
{
  ....
  virtual int
  ndimensions() const = 0;	

  virtual void
  compute_switch_coords(switch_id swid, coordinates& coords) const = 0;

  virtual void
  minimal_route_to_coords(
    const coordinates& src_coords,
    const coordinates& dest_coords,
    routable::path& path) const = 0;

  virtual int
  minimal_distance(
    const coordinates& src_coords,
    const coordinates& dest_coords) const = 0;

  virtual void
  get_productive_path(
    int dim,
    const coordinates& src,
    const coordinates& dst,
    routable::path& path) const = 0;
  ...
};
\end{CppCode}
The structured topology must have a well-defined number of dimensions, such as a 3D-torus or the number of levels in a tree.
The topology must also be able to map any \switchid to a unique set of coordinates.
Given two input sets of input coordinates, it should be able to perform the routing operation or compute the minimal distance between two points.
Finally, for adaptive routing purposes, the topology should map routing requests to the correct path.
For example, if I want to move in the X dimension in a 3D-torus, what path (port) is needed to make a productive step?
It can be that any step along that dimension is unproductive - you've already arrived.
The behavior is then undefined.

\section{Router}\label{sec:router}
The router has a simple public interface

\begin{CppCode}
class router :
  public sprockit::factory_type
{
...
  virtual void
  route(packet* pkt) = 0;

  virtual void
  minimal_route_to_node(
    node_id node_addr,
    routable::path& path) = 0;
    
  virtual void
  minimal_route_to_switch(
    switch_id sw_addr,
    routable::path& path) = 0;
...
};
\end{CppCode}

Different routers exist for the different routing algorithms: 	minimal, valiant, ugal.
The router objects are specific to a switch and can therefore store state information.
However, the router should query the topology object for any path-specific information, e.g.

\begin{CppCode}
void
structured_router::minimal_route_to_node(
  node_id dest_node_addr,
  routable::path& path)
{
  netlink_id endpoint_id(dest_node_addr / top_->num_nodes_per_netlink());
  //Query the topology for path info
  switch_id ej_addr = regtop_->endpoint_to_ejection_switch(endpoint_id, path.outport);
  if (ej_addr == my_addr_) {
    path.vc = 0;
  }
  else {
    minimal_route_to_switch(ej_addr, path);
  }
}
...
\end{CppCode}

For adaptive routing, a bit more work is done.
Each router is connect to a switch object which holds all the information about queue lengths, e.g.

\begin{CppCode}
int test_length = get_switch()->queue_length(paths[i].outport);
\end{CppCode}
allowing the router to select an alternate path if the congestion is too high. 


